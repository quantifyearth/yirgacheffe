{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#overview","title":"Overview","text":"<p>Yirgacheffe is a Python library that provides a declarative way of working with geospatial data, taking care of all the tedious tasks of aligning rasters, rasterizing polygons, and dealing with memory management and other hardware management issues. You can think of it as numpy or pandas but for geospatial data. Here's a quick example of calculating a species Area Of Habitat using Yirgacheffe:</p> <pre><code>import yirgaceffe as yg\n\nwith (\n    yg.read_raster(\"habitats.tif\") as habitat_map,\n    yg.read_raster('elevation.tif') as elevation_map,\n    yg.read_shape('species123.geojson') as range_map,\n):\n    refined_habitat = habitat_map.isin([...species habitat codes...])\n    refined_elevation = (elevation_map &gt;= species_min) &amp;&amp; (elevation_map &lt;= species_max)\n    aoh = refined_habitat * refined_elevation * range_polygon * area_per_pixel_map\n    print(f'Area of habitat: {aoh.sum()}')\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<p>Yirgacheffe is available via pypi, so can be installed with pip for example:</p> <pre><code>$ pip install yirgacheffe\n</code></pre>"},{"location":"#basic-features","title":"Basic features","text":""},{"location":"#layers","title":"Layers","text":"<p>They main unit of data in Yirgacheffe is a \"layer\", which wraps either a raster dataset or polygon data, and then you can do work on layers without having to worry (unless you choose to) about how they align. Yirgacheffe will automatically infer if you want to do an intersection of maps or a union of the maps based on the operators you use (see below for a full table). You can explicitly override that if you want.</p>"},{"location":"#expressions-on-layers","title":"Expressions on layers","text":"<p>Rather than working with arrays of pixel values as you would with say GDAL, Yirgacheffe lets you directly operate on layers without having to worry about reading and writing the individual values within.</p>"},{"location":"#lazy-loading-and-evaluation","title":"Lazy loading and evaluation","text":"<p>Yirgacheffe uses a technique from computer science called \"lazy evaluation\", which means that only when you resolve a calculation will Yirgacheffe do any work. So in the first code example given, the work is only calculated when you call the <code>sum()</code> method. All the other intermediary results such as <code>refined_habitat</code> and <code>refined_elevation</code> are not calculated either until that final <code>sum()</code> is called. You could easily call sum on those intermediaries if you wanted and get their results, and that would cause them to be evaluated then.</p> <p>Similarly, when you load a layer, be it a raster layer or a vector layer from polygon data, the full data for the file isn't loaded until it's needed for a calculation, and even then only the part of the data necessary will be loaded or rasterized. Furthermore, Yirgacheffe will load the data in chunks, letting you work with rasters bigger than those that would otherwise fit within your computer's memory.</p>"},{"location":"#automatic-expanding-and-contracting-layers","title":"Automatic expanding and contracting layers","text":"<p>When you load raster layers that aren't of equal geographic area (that is, they have a different origin, size, or both)then Yirgacheffe will do all the math internally to ensure that it aligns the pixels geospatially when doing calculations.</p> <p>If size adjustments are needed, then Yirgacheffe will infer from the calculations you're doing if it needs to either crop or enlarge layers. For instance, if you're summing two rasters it'll expand them to be the union of their two areas before adding them, filling in the missing parts with zeros. If you're multiplying or doing a logical AND of pixels then it'll find the intersection between the two rasters (as areas missing in one would cause the other layer to result in zero anyway).</p>"},{"location":"#direct-access-to-data","title":"Direct access to data","text":"<p>If doing per-layer operations isn't applicable for your application, you can read the pixel values for all layers (including VectorLayers) by calling <code>read_array</code> similarly to how you would for GDAL.</p>"},{"location":"#parallel-saving","title":"Parallel saving","text":"<p>There is a parallel version of save that can use multiple CPU cores at once to speed up work, that is added as an experimental feature for testing in our wider codebase, which will run concurrently the save over many threads.</p>"},{"location":"#gpu-support","title":"GPU support","text":"<p>Yirgacheffe has multiple backends, with more planned. Currently you can set the <code>YIRGACHEFFE_BACKEND</code> environmental variable to select which one to use. The default is <code>NUMPY</code>:</p> <ul> <li><code>NUMPY</code>: CPU based calculation using numpy</li> <li><code>MLX</code>: Apple/Intel GPU support with CPU fallback based on MLX</li> </ul> <p>Note that GPU isn't always faster than CPU - it very much depends on the workload, so testing your particular use-case is important.</p>"},{"location":"#about","title":"About","text":"<p>Yirgacheffe was created by Michael Dales whilst working on multiple geospatial projects as a way to hide the boilerplate associated with working with large raster and polygon geospatial datasets.</p> <p>The code for Yirgcheffe is available on Github.</p>"},{"location":"CODE_OF_CONDUCT/","title":"Contributor Covenant 3.0 Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We pledge to make our community welcoming, safe, and equitable for all.</p> <p>We are committed to fostering an environment that respects and promotes the dignity, rights, and contributions of all individuals, regardless of characteristics including race, ethnicity, caste, colour, age, physical characteristics, neurodiversity, disability, sex or gender, gender identity or expression, sexual orientation, language, philosophy or religion, national or social origin, socio-economic position, level of education, or other status. The same privileges of participation are extended to everyone who participates in good faith and in accordance with this Covenant.</p>"},{"location":"CODE_OF_CONDUCT/#encouraged-behaviours","title":"Encouraged Behaviours","text":"<p>While acknowledging differences in social norms, we all strive to meet our community's expectations for positive behaviour. We also understand that our words and actions may be interpreted differently than we intend based on culture, background, or native language.</p> <p>With these considerations in mind, we agree to behave mindfully toward each other and act in ways that centre our shared values, including:</p> <ol> <li>Respecting the purpose of our community, our activities, and our ways of gathering.</li> <li>Engaging kindly and honestly with others.</li> <li>Respecting different viewpoints and experiences.</li> <li>Taking responsibility for our actions and contributions.</li> <li>Gracefully giving and accepting constructive feedback.</li> <li>Committing to repairing harm when it occurs.</li> <li>Behaving in other ways that promote and sustain the well-being of our community.</li> </ol>"},{"location":"CODE_OF_CONDUCT/#restricted-behaviours","title":"Restricted Behaviours","text":"<p>We agree to restrict the following behaviours in our community. Instances, threats, and promotion of these behaviors are violations of this Code of Conduct.</p> <ol> <li>Harassment. Violating explicitly expressed boundaries or engaging in unnecessary personal attention after any clear request to stop.</li> <li>Character attacks. Making insulting, demeaning, or pejorative comments directed at a community member or group of people.</li> <li>Stereotyping or discrimination. Characterising anyone\u2019s personality or behaviour on the basis of immutable identities or traits.</li> <li>Sexualization. Behaving in a way that would generally be considered inappropriately intimate in the context or purpose of the community.</li> <li>Violating confidentiality. Sharing or acting on someone's personal or private information without their permission.</li> <li>Endangerment. Causing, encouraging, or threatening violence or other harm toward any person or group.</li> <li>Behaving in other ways that threaten the well-being of our community.</li> </ol>"},{"location":"CODE_OF_CONDUCT/#other-restrictions","title":"Other Restrictions","text":"<ol> <li>Misleading identity. Impersonating someone else for any reason, or pretending to be someone else to evade enforcement actions.</li> <li>Failing to credit sources. Not properly crediting the sources of content you contribute.</li> <li>Promotional materials. Sharing marketing or other commercial content in a way that is outside the norms of the community.</li> <li>Irresponsible communication. Failing to responsibly present content which includes, links or describes any other restricted behaviors.</li> </ol>"},{"location":"CODE_OF_CONDUCT/#reporting-an-issue","title":"Reporting an Issue","text":"<p>Tensions can occur between community members even when they are trying their best to collaborate. Not every conflict represents a code of conduct violation, and this Code of Conduct reinforces encouraged behaviours and norms that can help avoid conflicts and minimise harm.</p> <p>When an incident does occur, it is important to report it promptly. To report a possible violation, contact the lead project maintainer, Michael Dales, @mdales on github, or mwd24@cam.ac.uk by email.</p> <p>Community Moderators take reports of violations seriously and will make every effort to respond in a timely manner. They will investigate all reports of code of conduct violations, reviewing messages, logs, and recordings, or interviewing witnesses and other participants. Community Moderators will keep investigation and enforcement actions as transparent as possible while prioritising safety and confidentiality. In order to honour these values, enforcement actions are carried out in private with the involved parties, but communicating to the whole community may be part of a mutually agreed upon resolution.</p>"},{"location":"CODE_OF_CONDUCT/#addressing-and-repairing-harm","title":"Addressing and Repairing Harm","text":"<p>If an investigation by the Community Moderators finds that this Code of Conduct has been violated, the following enforcement ladder may be used to determine how best to repair harm, based on the incident's impact on the individuals involved and the community as a whole. Depending on the severity of a violation, lower rungs on the ladder may be skipped.</p> <p>1) Warning    1) Event: A violation involving a single incident or series of incidents.    2) Consequence: A private, written warning from the Community Moderators.    3) Repair: Examples of repair include a private written apology, acknowledgement of responsibility, and seeking clarification on expectations. 2) Temporarily Limited Activities    1) Event: A repeated incidence of a violation that previously resulted in a warning, or the first incidence of a more serious violation.    2) Consequence: A private, written warning with a time-limited cooldown period designed to underscore the seriousness of the situation and give the community members involved time to process the incident. The cooldown period may be limited to particular communication channels or interactions with particular community members.    3) Repair: Examples of repair may include making an apology, using the cooldown period to reflect on actions and impact, and being thoughtful about re-entering community spaces after the period is over. 3) Temporary Suspension    1) Event: A pattern of repeated violation which the Community Moderators have tried to address with warnings, or a single serious violation.    2) Consequence: A private written warning with conditions for return from suspension. In general, temporary suspensions give the person being suspended time to reflect upon their behaviour and possible corrective actions.    3) Repair: Examples of repair include respecting the spirit of the suspension, meeting the specified conditions for return, and being thoughtful about how to reintegrate with the community when the suspension is lifted. 4) Permanent Ban    1) Event: A pattern of repeated code of conduct violations that other steps on the ladder have failed to resolve, or a violation so serious that the Community Moderators determine there is no way to keep the community safe with this person as a member.    2) Consequence: Access to all community spaces, tools, and communication channels is removed. In general, permanent bans should be rarely used, should have strong reasoning behind them, and should only be resorted to if working through other remedies has failed to change the behaviour.    3) Repair: There is no possible repair in cases of this severity.</p> <p>This enforcement ladder is intended as a guideline. It does not limit the ability of Community Managers to use their discretion and judgment, in keeping with the best interests of our community.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public or other spaces. Examples of representing our community include using an official email address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 3.0, permanently available at https://www.contributor-covenant.org/version/3/0/.</p> <p>Contributor Covenant is stewarded by the Organisation for Ethical Source and licensed under CC BY-SA 4.0. To view a copy of this license, visit https://creativecommons.org/licenses/by-sa/4.0/</p> <p>For answers to common questions about Contributor Covenant, see the FAQ at https://www.contributor-covenant.org/faq. Translations are provided at https://www.contributor-covenant.org/translations. Additional enforcement and community guideline resources can be found at https://www.contributor-covenant.org/resources. The enforcement ladder was inspired by the work of Mozilla\u2019s code of conduct team.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v190-2692025","title":"v1.9.0 (26/9/2025)","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Added code of conduct to project.</li> <li>Added the ability to call <code>read_array</code> on expressions (before you could only call it on layers).</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>The first argument of MapProjection, the string defining the projection used is now validated with the pyproj library, and can be in any from the pyproj <code>from_string</code> takes: Well Known Text (WKT) or \"epsg:4326\" or \"esri:54009\" etc. The name function still returns the WKT representation for backwards compatibility.</li> <li>The functions <code>pixel_from_latlng</code> and <code>latlng_from_pixel</code> will work regardless of the underlying map projection.</li> </ul>"},{"location":"changelog/#v181-2592025","title":"v1.8.1 (25/9/2025)","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Fixed issue whereby calling <code>set_window_for_intersection</code> would fail if the pixel alignment on a vector layer was rounded unfortunately.</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>More documentation updates.</li> </ul>"},{"location":"changelog/#v180-2492025","title":"v1.8.0 (24/9/2025)","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Mkdocs based documentation.</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>Modernised type hints to use latest Python standards.</li> </ul>"},{"location":"changelog/#v179-2392025","title":"v1.7.9 (23/9/2025)","text":""},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Fix type inference for expressions so that <code>to_geotiff</code> selects correct GeoTIFF file type to store results as.</li> </ul>"},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>Improved typing of methods that take a filename to use both Path and str.</li> </ul>"},{"location":"changelog/#v178-1792025","title":"v1.7.8 (17/9/2025)","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Added marker for mypy that Yirgacheffe has type annotations</li> </ul>"},{"location":"changelog/#v177-892025","title":"v1.7.7 (8/9/2025)","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>Automatically set rlimit for NOFILES so that parallel operations of machines with many cores don't run out of file descriptors.</li> </ul>"},{"location":"changelog/#removed","title":"Removed","text":"<ul> <li>Removed internal classes <code>LayerOperation</code>, <code>LayerMathMixin</code>, and <code>LayerConstant</code> from public interface.</li> </ul>"},{"location":"changelog/#v176-2082025","title":"v1.7.6 (20/8/2025)","text":""},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>Fixed issue whereby vector layers without explicit projection would use the abstract rather than concrete area value when generating a target raster.</li> </ul>"},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>Added a core wrapper <code>constant</code> to save people using <code>ConstantLayer</code> explicitly</li> <li>Added a core wrapper <code>read_narrow_raster</code> to save people using <code>UniformAreaLayer</code> explicitly</li> </ul>"},{"location":"changelog/#v175-1982025","title":"v1.7.5 (19/8/2025)","text":""},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>Minor improvements to GitHub Actions workflows</li> </ul>"},{"location":"changelog/#v174-1982025","title":"v1.7.4 (19/8/2025)","text":""},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li>Fixed bug whereby reads from within a single tile that has nodata values in a group layer used the wrong numpy call to check for nan.</li> </ul>"},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>Added <code>isnan</code> operator.</li> </ul>"},{"location":"changelog/#v173-1882025","title":"v1.7.3 (18/8/2025)","text":""},{"location":"changelog/#fixed_4","title":"Fixed","text":"<ul> <li>Fixed an issue introduced in 1.7.0 where <code>find_intersection</code> and <code>find_union</code> used the raw, non-pixel aligned area envelope.</li> </ul>"},{"location":"changelog/#v172-1482025","title":"v1.7.2 (14/8/2025)","text":""},{"location":"changelog/#changed_5","title":"Changed","text":"<ul> <li>Added the option to set <code>parallelism=True</code> rather than just a number when calling <code>to_geotiff</code>, allowing Yirgacheffe to select the number of CPU cores to use for parallel operations.</li> </ul>"},{"location":"changelog/#v171-1482025","title":"v1.7.1 (14/8/2025)","text":""},{"location":"changelog/#fixed_5","title":"Fixed","text":"<ul> <li>Fixed an issue whereby if you used the MLX backend and called <code>read_array</code> the return value was sometimes an mlx array rather than a numpy array.</li> </ul>"},{"location":"changelog/#v17-1482025","title":"v1.7 (14/8/2025)","text":""},{"location":"changelog/#added_6","title":"Added","text":"<ul> <li>Support the ability to create VectorLayers that don't have a pixel scale or projection added. These layers will have the correct pixel scale and projection calculated when calculations on layers are saved or aggregated based on the other raster layers used in the calculation.</li> <li>Added MapProjection object to replace PixelScale objects and projection strings being separate parameters.</li> </ul>"},{"location":"api/core/","title":"Core","text":"<p>To get started with yirgacheffe you can import data using the following core methods.</p>"},{"location":"api/core/#yirgacheffe.read_raster","title":"<code>read_raster(filename, band=1, ignore_nodata=False)</code>","text":"<p>Open a raster file (e.g., GeoTIFF).</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Path of raster file to open.</p> required <code>band</code> <code>int</code> <p>For multi-band rasters, which band to use (defaults to first if not specified).</p> <code>1</code> <code>ignore_nodata</code> <code>bool</code> <p>If the GeoTIFF has a NODATA value, don't substitute that value for NaN.</p> <code>False</code> <p>Returns:</p> Type Description <code>RasterLayer</code> <p>An layer representing the raster data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import yirgacheffe as yg\n&gt;&gt;&gt; with yg.read_raster('test.tif') as layer:\n...     total = layer.sum()\n</code></pre>"},{"location":"api/core/#yirgacheffe.read_shape","title":"<code>read_shape(filename, projection=None, where_filter=None, datatype=None, burn_value=1)</code>","text":"<p>Open a polygon file (e.g., GeoJSON, GPKG, or ESRI Shape File).</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Path of vector file to open.</p> required <code>projection</code> <code>MapProjection | tuple[str, tuple[float, float]] | None</code> <p>The map projection to use.</p> <code>None</code> <code>where_filter</code> <code>str | None</code> <p>For use with files with many entries (e.g., GPKG), applies this filter to the data.</p> <code>None</code> <code>datatype</code> <code>dtype | None</code> <p>Specify the data type of the raster data generated.</p> <code>None</code> <code>burn_value</code> <code>int | float | str</code> <p>The value of each pixel in the polygon.</p> <code>1</code> <p>Returns:</p> Type Description <code>VectorLayer</code> <p>An layer representing the vector data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import yirgacheffe as yg\n&gt;&gt;&gt; with yg.read_shape('range.gpkg') as layer:\n...    ...\n</code></pre>"},{"location":"api/core/#yirgacheffe.read_shape_like","title":"<code>read_shape_like(filename, like, where_filter=None, datatype=None, burn_value=1)</code>","text":"<p>Open a polygon file (e.g., GeoJSON, GPKG, or ESRI Shape File).</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Path of vector file to open.</p> required <code>like</code> <code>YirgacheffeLayer</code> <p>Another layer that has a projection and pixel scale set. This layer will use the same projection and pixel scale as that one.</p> required <code>where_filter</code> <code>str | None</code> <p>For use with files with many entries (e.g., GPKG), applies this filter to the data.</p> <code>None</code> <code>datatype</code> <code>dtype | None</code> <p>Specify the data type of the raster data generated.</p> <code>None</code> <code>burn_value</code> <code>int | float | str</code> <p>The value of each pixel in the polygon.</p> <code>1</code> <p>Returns:</p> Type Description <code>VectorLayer</code> <p>An layer representing the vector data.</p>"},{"location":"api/core/#yirgacheffe.read_rasters","title":"<code>read_rasters(filenames, tiled=False)</code>","text":"<p>Open a set of raster files (e.g., GeoTIFFs) as a single layer.</p> <p>Parameters:</p> Name Type Description Default <code>filenames</code> <code>Sequence[Path | str]</code> <p>List of paths of raster files to open.</p> required <code>tiled</code> <code>bool</code> <p>If you know that the rasters for a regular tileset, then setting this flag allows Yirgacheffe to perform certain optimisations that significantly improve performance for this use case.</p> <code>False</code> <p>Returns:</p> Type Description <code>GroupLayer</code> <p>An layer representing the raster data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import yirgacheffe as yg\n&gt;&gt;&gt; with yg.read_rasters(['tile_N10_E10.tif', 'tile_N20_E10.tif']) as all_tiles:\n...    ...\n</code></pre>"},{"location":"api/core/#yirgacheffe.constant","title":"<code>constant(value)</code>","text":"<p>Generate a layer that has the same value in all pixels regardless of scale, projection, and area.</p> <p>Generally this should not be necessary unless you must have the constant as the first term in an expression, as Yirgacheffe will automatically convert numbers into constant layers. However if the constant is the first term in the expression it must be wrapped by this call otherwise Python will not know that it should be part of the Yirgacheffe expression.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int | float</code> <p>The value to be in each pixel of the expression term.</p> required <p>Returns:</p> Type Description <code>ConstantLayer</code> <p>A constant layer of the provided value.</p>"},{"location":"api/expressions/","title":"Expressions","text":"<p>The power of Yirgacheffe comes from being able to operate on geospatial data as if it was an elemental type. You can combine and work with layers without worrying about individual pixels or how different layers are aligned spatially. Assuming your data is in the same projection and pixel scale, you can just get on working. For example, here's how a simple Area of Habitat calculation might be implemented:</p> <pre><code>import yirgaceffe as yg\n\nwith (\n    yg.read_raster(\"habitats.tif\") as habitat_map,\n    yg.read_raster('elevation.tif') as elevation_map,\n    yg.read_shape('species123.geojson') as range_polygon\n):\n    refined_habitat = habitat_map.isin([...species habitat codes...])\n    refined_elevation = (elevation_map &gt;= species_min) &amp;&amp; (elevation_map &lt;= species_max)\n    aoh = refined_habitat * refined_elevation * range_polygon\n    print(f'area for species 123: {aoh.sum()}')\n    aoh.to_geotiff(\"result.tif\")\n</code></pre>"},{"location":"api/expressions/#operators","title":"Operators","text":""},{"location":"api/expressions/#add-subtract-multiple-divide","title":"Add, subtract, multiple, divide","text":"<p>Pixel-wise addition, subtraction, multiplication or division (both true and floor division), and remainder. Either between arrays, or with constants:</p> <pre><code>with (\n    yg.read_raster('test1.tif') as layer1,\n    yg.read_raster('test2.tif') as layer2\n):\n    result = layer1 + layer2\n    result.to_geotiff(\"result.tif\")\n</code></pre> <p>or</p> <pre><code>with yg.read_raster('test1.tif') as layer1:\n    result = layer1 * 42.0\n    result.to_geotiff(\"result.tif\")\n</code></pre>"},{"location":"api/expressions/#boolean-testing","title":"Boolean testing","text":"<p>Testing for equality, less than, less than or equal, greater than, and greater than or equal are supported on layers, along with logical or and logical and, as per this example, where <code>elevation_upper</code> and <code>elevation_lower</code> are scalar values:</p> <pre><code>filtered_elevation = (min_elevation_map &lt;= elevation_upper) &amp; (max_elevation_map &gt;= elevation_lower)\n</code></pre>"},{"location":"api/expressions/#power","title":"Power","text":"<p>Pixel-wise raising to a constant power:</p> <pre><code>with yg.read_raster('test1.tif') as layer1:\n    calc = layer1 ** 0.65\n    calc.save(\"result.tif\")\n</code></pre>"},{"location":"api/expressions/#log-exp-clip-etc","title":"Log, Exp, Clip, etc.","text":"<p>The following math operators common to numpy and other libraries are currently supported:</p> <ul> <li>abs</li> <li>ceil</li> <li>clip</li> <li>exp</li> <li>exp2</li> <li>floor</li> <li>isin</li> <li>log</li> <li>log2</li> <li>log10</li> <li>maximum</li> <li>minimum</li> <li>nan_to_num</li> <li>round</li> </ul> <p>Typically these can be invoked either on a layer as a method:</p> <pre><code>calc = layer1.log10()\n</code></pre> <p>Or via the operators module, as it's sometimes nicer to do it this way when chaining together operations in a single expression:</p> <pre><code>import yirgaceffe.operators as yo\n\ncalc = yo.log10(layer1 / layer2)\n</code></pre>"},{"location":"api/expressions/#2d-matrix-convolution","title":"2D matrix convolution","text":"<p>To facilitate image processing algorithms you can supply a weight matrix to generate a processed image. Currently this support only works for square weight matrices of an odd size.</p> <p>For example, to apply a blur function to a raster:</p> <pre><code>blur_filter = np.array([\n    [0.0, 0.1, 0.0],\n    [0.1, 0.6, 0.1],\n    [0.0, 0.1, 0.0],\n])\nwith yg.read_raster('original.tif') as layer1:\n    calc = layer1.conv2d(blur_filter)\n    calc.to_geotiff(\"blurred.tif\")\n</code></pre>"},{"location":"api/expressions/#type-conversion","title":"Type conversion","text":"<p>Similar to numpy and other Python numerical libraries, Yirgacheffe will automatically deal with simple type conversion where possible, however sometimes explicit conversion is either necessary or desired. Similar to numpy, there is an <code>astype</code> operator that lets you set the conversion:</p> <pre><code>from yirgacheffe.operations import DataType\n\n\nwith yg.read_raster('float_data.tif') as float_layer:\n    int_layer = float_layer.astype(DataType.Int32)\n</code></pre>"},{"location":"api/expressions/#apply","title":"Apply","text":"<p>You can specify a function that takes either data from one layer or from two layers, and returns the processed data. There's two version of this: one that lets you specify a numpy function that'll be applied to the layer data as an array, or one that is more shader like that lets you do pixel wise processing.</p> <p>Firstly the numpy version looks like this:</p> <pre><code>def is_over_ten(input_array):\n    return numpy.where(input_array &gt; 10.0, 0.0, 1.0)\n\nwith yg.read_raster(\"test1.tif\") as layer1:\n    calc = layer1.numpy_apply(is_over_ten)\n    calc.to_geotiff(\"result.tif\")\n</code></pre> <p>or</p> <pre><code>def simple_add(first_array, second_array):\n    return first_array + second_array\n\nwith (\n    yg.read_raster(\"test1.tif\") as layer1,\n    yg.read_raster(\"test2.tif\") as layer2\n):\n    calc = layer1.numpy_apply(simple_add, layer2)\n    calc.to_geotiff(\"result.tif\")\n</code></pre> <p>If you want to do something specific on the pixel level, then you can also do that, again either on a unary or binary form.</p> <pre><code>def is_over_ten(input_pixel):\n    return 1.0 if input_pixel &gt; 10 else 0.0\n\nwith yg.read_raster(\"test1.tif\") as layer1:\n    calc = layer1.shader_apply(is_over_ten)\n    calc.to_geotiff(result)\n</code></pre> <p>Note:</p> <ol> <li>Using <code>numpy_apply</code> prevents GPU optimisations occuring, so should be used as a last resort.</li> <li>In general <code>numpy_apply</code> is considerably faster than <code>shader_apply</code>.</li> </ol>"},{"location":"api/expressions/#storing-the-results-of-expressions","title":"Storing the results of expressions","text":"<p>There are three ways to store the result of a computation.</p>"},{"location":"api/expressions/#saving-to-a-geotiff","title":"Saving to a GeoTIFF","text":"<p>In all the above examples we use the <code>to_geotiff</code> call, to which you pass a filename for a GeoTIFF, into which the results will be written. You can optionally pass a callback to save which will be called for each chunk of data processed and give you the amount of progress made so far as a number between 0.0 and 1.0:</p> <pre><code>def print_progress(p)\n    print(f\"We have made {p * 100} percent progress\")\n\n...\n\ncalc.to_geotiff(result, callback=print_progress)\n</code></pre>"},{"location":"api/expressions/#aggregations","title":"Aggregations","text":"<p>The alternative is to call aggregation functions such as <code>sum</code>, <code>min</code>, or <code>max</code> which will give you a single value by aggregating the data within the layer or expression:</p> <pre><code>with (\n    RasterLayer.layer_from_file(...) as area_layer,\n    VectorLayer(...) as mask_layer\n):\n    intersection = RasterLayer.find_intersection([area_layer, mask_layer])\n    area_layer.set_intersection_window(intersection)\n    mask_layer.set_intersection_window(intersection)\n\n    calc = area_layer * mask_layer\n\n    total_area = calc.sum()\n</code></pre>"},{"location":"api/expressions/#as-numpy-arrays","title":"As numpy arrays","text":"<p>Finally, if you want to read the pixel values of either a layer or an expression, you can call <code>read_array</code>:</p> <pre><code>import yirgacheffe as yg\n\nwith (\n    yg.read_raster(\"test1.tif\") as layer1,\n    yg.read_raster(\"test2.tif\") as layer2\n):\n    result = layer1 + layer2\n    pixels = result.read_array(10, 10, 100, 100)\n</code></pre>"},{"location":"api/operators/","title":"Operators","text":"<p>The following symbolic operators are supported on layers:</p> Symbol Operator + add - subtract * multiply / division // floor division % mod ^ power == equal != not equal &lt; less than &lt;= less than or equal &gt; greater than &gt;= greater than or equal &amp; logical and | logical or <p>On a layer you can also invoke the following operations using <code>layer.operator(...)</code> syntax:</p> Operator abs ceil clip conv2d exp exp2 floor isin isnan log log10 log2 nan_to_num <p>You can also call the following methods on <code>yirgacheffe.operators</code>:</p>"},{"location":"api/operators/#yirgacheffe.operators.abs","title":"<code>abs = LayerOperation.abs</code>  <code>module-attribute</code>","text":""},{"location":"api/operators/#yirgacheffe.operators.ceil","title":"<code>ceil = LayerOperation.ceil</code>  <code>module-attribute</code>","text":""},{"location":"api/operators/#yirgacheffe.operators.exp","title":"<code>exp = LayerOperation.exp</code>  <code>module-attribute</code>","text":""},{"location":"api/operators/#yirgacheffe.operators.exp2","title":"<code>exp2 = LayerOperation.exp2</code>  <code>module-attribute</code>","text":""},{"location":"api/operators/#yirgacheffe.operators.floor","title":"<code>floor = LayerOperation.floor</code>  <code>module-attribute</code>","text":""},{"location":"api/operators/#yirgacheffe.operators.isin","title":"<code>isin = LayerOperation.isin</code>  <code>module-attribute</code>","text":""},{"location":"api/operators/#yirgacheffe.operators.log","title":"<code>log = LayerOperation.log</code>  <code>module-attribute</code>","text":""},{"location":"api/operators/#yirgacheffe.operators.log10","title":"<code>log10 = LayerOperation.log10</code>  <code>module-attribute</code>","text":""},{"location":"api/operators/#yirgacheffe.operators.log2","title":"<code>log2 = LayerOperation.log2</code>  <code>module-attribute</code>","text":""},{"location":"api/operators/#yirgacheffe.operators.maximum","title":"<code>maximum = LayerOperation.maximum</code>  <code>module-attribute</code>","text":""},{"location":"api/operators/#yirgacheffe.operators.nan_to_num","title":"<code>nan_to_num = LayerOperation.nan_to_num</code>  <code>module-attribute</code>","text":""},{"location":"api/operators/#yirgacheffe.operators.round","title":"<code>round = LayerOperation.round</code>  <code>module-attribute</code>","text":""},{"location":"api/operators/#yirgacheffe.operators.where","title":"<code>where = LayerOperation.where</code>  <code>module-attribute</code>","text":""},{"location":"api/classes/area/","title":"<code>Area</code>","text":"<p>Class to hold a geospatial area of data in the given projection.</p> <p>Parameters:</p> Name Type Description Default <code>left</code> <code>float</code> <p>Left most point in the projection space.</p> required <code>top</code> <code>float</code> <p>Top most point in the projection space.</p> required <code>right</code> <code>float</code> <p>Right most point in the projection space.</p> required <code>bottom</code> <code>float</code> <p>Bottom most point in the projection space.</p> required <p>Attributes:</p> Name Type Description <code>left</code> <code>float</code> <p>Left most point in the projection space.</p> <code>top</code> <code>float</code> <p>Top most point in the projection space.</p> <code>right</code> <code>float</code> <p>Right most point in the projection space.</p> <code>bottom</code> <code>float</code> <p>Bottom most point in the projection space.</p>"},{"location":"api/classes/area/#yirgacheffe.Area.is_world","title":"<code>is_world</code>  <code>property</code>","text":"<p>Returns true if this is a global area, independent of projection.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the Area was created with <code>world</code> otherwise False.</p>"},{"location":"api/classes/area/#yirgacheffe.Area.grow","title":"<code>grow(offset)</code>","text":"<p>Expand the area in all directions by the given amount.</p> <p>Generates a new area that is an expanded version of the current area.</p> <p>Parameters:</p> Name Type Description Default <code>offset</code> <code>float</code> <p>The amount by which to grow the area.</p> required <p>Returns:</p> Type Description <code>Area</code> <p>A new area of the expanded size.</p>"},{"location":"api/classes/area/#yirgacheffe.Area.overlaps","title":"<code>overlaps(other)</code>","text":"<p>Check if this area overlaps with another area.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Area</code> <p>The other area to compare this area with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the two areas intersect, otherwise false.</p>"},{"location":"api/classes/area/#yirgacheffe.Area.world","title":"<code>world()</code>  <code>staticmethod</code>","text":"<p>Creates an area that covers the entire planet.</p> <p>Returns:</p> Type Description <code>Area</code> <p>An area where the extents are nan, but is_world returns true.</p>"},{"location":"api/classes/mapprojection/","title":"<code>MapProjection</code>","text":"<p>Records the map projection and the size of the pixels in a layer.</p> <p>This superceeeds the old PixelScale class, which will be removed in version 2.0.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>The map projection used in WKT format, or as \"epsg:xxxx\" or \"esri:xxxx\".</p> required <code>xstep</code> <code>float</code> <p>The number of units horizontal distance a step of one pixel makes in the map projection.</p> required <code>ystep</code> <code>float</code> <p>The number of units vertical distance a step of one pixel makes in the map projection.</p> required <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The map projection used in WKT format.</p> <code>xstep</code> <p>The number of units horizontal distance a step of one pixel makes in the map projection.</p> <code>ystep</code> <p>The number of units vertical distance a step of one pixel makes in the map projection.</p>"},{"location":"api/classes/window/","title":"<code>Window</code>","text":"<p>Class to hold the pixel dimensions of data in the given projection.</p> <p>Parameters:</p> Name Type Description Default <code>xoff</code> <code>int</code> <p>X axis offset.</p> required <code>yoff</code> <code>int</code> <p>Y axis offset.</p> required <code>xsize</code> <code>int</code> <p>Width of data in pixels.</p> required <code>ysize</code> <code>int</code> <p>Height of data in pixels.</p> required <p>Attributes:</p> Name Type Description <code>xoff</code> <code>int</code> <p>X axis offset.</p> <code>yoff</code> <code>int</code> <p>Y axis offset.</p> <code>xsize</code> <code>int</code> <p>Width of data in pixels.</p> <code>ysize</code> <code>int</code> <p>Height of data in pixels.</p>"},{"location":"api/classes/window/#yirgacheffe.Window.as_array_args","title":"<code>as_array_args</code>  <code>property</code>","text":"<p>A tuple containing xoff, yoff, xsize, and ysize.</p>"},{"location":"api/classes/window/#yirgacheffe.Window.grow","title":"<code>grow(pixels)</code>","text":"<p>Expand the area in all directions by the given amount.</p> <p>Generates a new window that is an expanded version of the current window.</p> <p>Parameters:</p> Name Type Description Default <code>pixels</code> <code>int</code> <p>The amount by which to grow the window in pixels.</p> required <p>Returns:</p> Type Description <code>Window</code> <p>A new window of the expanded size.</p>"},{"location":"api/enums/datatype/","title":"DataType","text":"<p>               Bases: <code>Enum</code></p> <p>Represents the type of data returned by a layer.</p> <p>This enumeration defines the valid data types supported by Yirgacheffe, and is what is returned by  calling <code>datatype</code> on a layer or expression, and can be passed to <code>astype</code> to convert values between types.</p> <p>Attributes:</p> Name Type Description <code>Float32</code> <p>32 bit floating point value</p> <code>Float64</code> <p>64 bit floating point value</p> <code>Byte</code> <p>Unsigned 8 bit integer value</p> <code>Int8</code> <p>Signed 8 bit integer value</p> <code>Int16</code> <p>Signed 16 bit integer value</p> <code>Int32</code> <p>Signed 32 bit integer value</p> <code>Int64</code> <p>Signed 64 bit integer value</p> <code>UInt8</code> <p>Unsigned 8 bit integer value</p> <code>UInt16</code> <p>Unsigned 16 bit integer value</p> <code>UInt32</code> <p>Unsigned 32 bit integer value</p> <code>UInt64</code> <p>Unsigned 64 bit integer value</p>"}]}